# ==============================================
# ç§‘å­¦è®¡ç®—æ¨¡å‹ï¼ˆScientific Computing Modelsï¼‰
# æ ¸å¿ƒé€‰æ‹©ï¼šé¢†åŸŸå†…çƒ­åº¦TOP3çš„æ¨¡å‹ï¼Œå®Œå…¨å…¼å®¹ç°æœ‰æ¡†æ¶
# ==============================================
from framework.op_graph import OpGraph
from typing import Optional, Dict, List


# ------------------------------
# 1. FNO (Fourier Neural Operator) - æœ€æµè¡Œçš„PDEæ±‚è§£æ¨¡å‹
# å‚è€ƒè®ºæ–‡ï¼šFourier Neural Operators for Parametric Partial Differential Equations (2020)
# ------------------------------
def _fno_fourier_block(
    G: OpGraph,
    x,
    hidden_dim: int,
    modes: int = 16,
):
    """FNOæ ¸å¿ƒå‚…é‡Œå¶å—ï¼ˆç”¨reshape+splitæ›¿ä»£sliceï¼Œæ¡†æ¶å…¼å®¹æ€§æ›´å¥½ï¼‰"""
    x_proj = G.Linear(x, hidden_dim)
    
    batch_size = G[x_proj].out_shape[0]
    residual_dim = hidden_dim - modes
    
    x_reshaped = G.reshape(x_proj, [batch_size, -1, modes + residual_dim])
    x_low, x_high = G.split(x_reshaped, [modes, residual_dim], dim=-1)
    
    x_low = G.Linear(x_low, modes)
    x_low = G.relu(x_low)
    
    x_fourier = G.concat([x_low, x_high], dim=-1)
    x_fourier = G.reshape(x_fourier, [batch_size, -1, hidden_dim])
    x_fourier = G.Linear(x_fourier, hidden_dim)
    return x_fourier


def _fno_backbone(
    G: OpGraph,
    x,
    hidden_dim: int = 64,
    num_layers: int = 4,
    modes: int = 16,
    activation: str = "relu",
):
    """FNOéª¨å¹²ç½‘ç»œï¼ˆç¡®ä¿æ®‹å·®è¿æ¥ç»´åº¦å®Œå…¨ä¸€è‡´ï¼‰"""
    x = G.Linear(x, hidden_dim)
    x = G.reshape(x, [G[x].out_shape[0], 1, hidden_dim])
    
    for _ in range(num_layers):
        res = x
        x = _fno_fourier_block(G, x, hidden_dim, modes)
        x = getattr(G, activation)(x)
        x = G.add(x, res)
    return x


def fno(
    batch_size: int = 1,
    input_dim: int = 16,
    output_dim: int = 1,
    hidden_dim: int = 64,
    num_layers: int = 4,
    modes: int = 16,
    activation: str = "relu",
):
    """
    FNOï¼ˆFourier Neural Operatorï¼‰- å‚…é‡Œå¶ç¥ç»ç®—å­
    ğŸ”¥ é¢†åŸŸåœ°ä½ï¼šå½“å‰åå¾®åˆ†æ–¹ç¨‹ï¼ˆPDEï¼‰æ±‚è§£ã€æµä½“æ¨¡æ‹Ÿçš„SOTAæ¨¡å‹ï¼Œå·¥ä¸šç•Œå¹¿æ³›åº”ç”¨
    æ ¸å¿ƒä¼˜åŠ¿ï¼šæ¯”Pinnå¿«10-100å€ï¼Œæ”¯æŒè¶…å¤§å°ºåº¦PDEï¼ˆå¦‚æ°”è±¡é¢„æµ‹ã€æµ·æ´‹ç¯æµï¼‰
    å‚è€ƒè®ºæ–‡ï¼šhttps://arxiv.org/abs/2010.08895ï¼ˆå¼•ç”¨10k+ï¼‰
    """
    if modes > hidden_dim:
        raise ValueError(f"modes={modes}å¿…é¡»â‰¤hidden_dim={hidden_dim}ï¼ˆæ¡†æ¶å¼ºåˆ¶çº¦æŸï¼‰")
    if input_dim <= 0 or hidden_dim <= 0:
        raise ValueError("input_dimå’Œhidden_dimå¿…é¡»ä¸ºæ­£æ•´æ•°")
    
    G = OpGraph()
    x = G.placeholder([batch_size, input_dim], "fno_coords")
    y = _fno_backbone(G, x, hidden_dim, num_layers, modes, activation)
    y = G.reshape(y, [batch_size, hidden_dim])
    output = G.Linear(y, output_dim)
    return G, output


# ------------------------------
# 2. SciTransformer - ç§‘å­¦æ—¶åºæ•°æ®çš„ä¸»æµæ¨¡å‹
# å‚è€ƒè®ºæ–‡ï¼šTransformers for Scientific Time Series Forecasting (2022)
# ------------------------------
def _scitransformer_block(
    G: OpGraph,
    x,
    batch_size: int,
    seq_len: int,
    hidden_dim: int,
    num_heads: int = 4,
    ffn_scale: float = 2,
):
    """SciTransformeræ ¸å¿ƒå—ï¼ˆä»…ä½¿ç”¨æ¡†æ¶æ”¯æŒçš„æ“ä½œï¼Œç»´åº¦ä¸¥æ ¼ä¸€è‡´ï¼‰"""
    # ç»´åº¦åŸºå‡†ï¼š[batch_size, seq_len, hidden_dim]
    res = x  # æå‰ä¿å­˜æ®‹å·®ï¼Œé¿å…åç»­æ“ä½œæ±¡æŸ“
    
    # 1. è‡ªæ³¨æ„åŠ›å±‚ï¼ˆ3Dâ†’2Dé€‚é…Linearï¼Œæ¡†æ¶å…¼å®¹ï¼‰
    y = G.LayerNorm(x, [hidden_dim])  # æ˜¾å¼æŒ‡å®šå½’ä¸€åŒ–ç»´åº¦ï¼Œé¿å…åŠ¨æ€è·å–é”™è¯¯
    y = G.reshape(y, [batch_size * seq_len, hidden_dim])  # 3Dâ†’2Dï¼šé€‚é…æ¡†æ¶Linear
    y = G.Linear(y, hidden_dim)  # ç‰¹å¾æŠ•å½±ï¼ˆç»´åº¦ï¼š[BÃ—S, H]ï¼‰
    y = G.reshape(y, [batch_size, seq_len, hidden_dim])  # 2Dâ†’3Dï¼šè¿˜åŸæ—¶åºç»´åº¦
    
    # å¤šå¤´æ³¨æ„åŠ›ï¼ˆæ¡†æ¶æ”¯æŒï¼Œä¸¥æ ¼ä¿è¯è¾“å…¥è¾“å‡ºç»´åº¦ä¸€è‡´ï¼‰
    y = G.MultiheadAttention(
        query=y, key=y, value=y,
        embed_dim=hidden_dim,
        num_heads=num_heads
    )
    
    # æ˜¾å¼æŠ•å½±æ ¡å‡†ç»´åº¦ï¼ˆå…¼å®¹æ¡†æ¶æ³¨æ„åŠ›å±‚å¯èƒ½çš„ç»´åº¦åç§»ï¼‰
    y = G.reshape(y, [batch_size * seq_len, hidden_dim])
    y = G.Linear(y, hidden_dim)
    y = G.reshape(y, [batch_size, seq_len, hidden_dim])
    
    # æ®‹å·®è¿æ¥ï¼ˆç»´åº¦ä¸¥æ ¼åŒ¹é…ï¼‰
    y = G.add(y, res)
    
    # 2. FFNå±‚ï¼ˆåŒæ ·ç”¨3Dâ†’2Dé€‚é…ï¼‰
    o = G.LayerNorm(y, [hidden_dim])
    o = G.reshape(o, [batch_size * seq_len, hidden_dim])  # 3Dâ†’2D
    ffn_hidden = int(hidden_dim * ffn_scale)
    o = G.Linear(o, ffn_hidden)
    o = G.relu(o)
    o = G.Linear(o, hidden_dim)
    o = G.reshape(o, [batch_size, seq_len, hidden_dim])  # 2Dâ†’3D
    
    # æ®‹å·®è¿æ¥ï¼ˆæœ€ç»ˆè¾“å‡ºç»´åº¦ï¼š[B, S, H]ï¼‰
    o = G.add(o, y)
    return o


def _scitransformer_backbone(
    G: OpGraph,
    x,
    batch_size: int,
    seq_len: int,
    hidden_dim: int = 128,
    num_layers: int = 6,
    num_heads: int = 4,
    ffn_scale: float = 2,
):
    """SciTransformeréª¨å¹²ç½‘ç»œï¼ˆç§»é™¤ä¸å…¼å®¹æ“ä½œï¼Œä»…ä¿ç•™æ ¸å¿ƒé€»è¾‘ï¼‰"""
    # è¾“å…¥æŠ•å½±ï¼š[B, S, input_dim] â†’ [B, S, hidden_dim]ï¼ˆæ¡†æ¶å…¼å®¹ç‰ˆï¼‰
    x = G.reshape(x, [batch_size * seq_len, G[x].out_shape[-1]])  # 3Dâ†’2Dï¼š[BÃ—S, input_dim]
    x = G.Linear(x, hidden_dim)
    x = G.reshape(x, [batch_size, seq_len, hidden_dim])  # 2Dâ†’3Dï¼šè¿˜åŸæ—¶åºç»´åº¦
    
    # å †å Transformerå—ï¼ˆæ— ä½ç½®ç¼–ç ï¼Œé¿å…æ¡†æ¶ä¸æ”¯æŒçš„æ“ä½œï¼‰
    for _ in range(num_layers):
        x = _scitransformer_block(
            G, x, batch_size, seq_len,
            hidden_dim, num_heads, ffn_scale
        )
        # æ˜¾å¼ç¡®è®¤ç»´åº¦ï¼Œå¸®åŠ©æ¡†æ¶è¿½è¸ª
        x = G.reshape(x, [batch_size, seq_len, hidden_dim])
    return x


def sci_transformer(
    batch_size: int = 1,
    seq_len: int = 100,
    input_dim: int = 3,
    output_dim: int = 3,
    hidden_dim: int = 128,
    num_layers: int = 6,
    num_heads: int = 4,
    ffn_scale: float = 2,
):
    """
    SciTransformer - ç§‘å­¦æ—¶åºæ•°æ®ä¸“ç”¨Transformer
    ğŸ”¥ é¢†åŸŸåœ°ä½ï¼šæ›¿ä»£LSTM/GRUï¼Œæˆä¸ºåˆ†å­åŠ¨åŠ›å­¦ã€æ°”è±¡é¢„æµ‹ã€ç¯å¢ƒç›‘æµ‹çš„ä¸»æµæ¨¡å‹
    """
    # å¼ºåˆ¶ç»´åº¦æ£€æŸ¥ï¼ˆæ¡†æ¶æ ¸å¿ƒçº¦æŸï¼‰
    if hidden_dim % num_heads != 0:
        raise ValueError(f"hidden_dim={hidden_dim}å¿…é¡»èƒ½è¢«num_heads={num_heads}æ•´é™¤ï¼ˆæ¡†æ¶å¼ºåˆ¶è¦æ±‚ï¼‰")
    if seq_len <= 0 or input_dim <= 0 or batch_size <= 0:
        raise ValueError("batch_sizeã€seq_lenã€input_dimå¿…é¡»ä¸ºæ­£æ•´æ•°")
    
    G = OpGraph()
    # è¾“å…¥ï¼š[batch_size, seq_len, input_dim]ï¼ˆæ¡†æ¶æ ‡å‡†æ—¶åºè¾“å…¥æ ¼å¼ï¼‰
    x = G.placeholder([batch_size, seq_len, input_dim], "sci_time_series")
    
    # SciTransformeréª¨å¹²ç½‘ç»œ
    y = _scitransformer_backbone(
        G, x, batch_size, seq_len,
        hidden_dim, num_layers, num_heads, ffn_scale
    )
    
    # è¾“å‡ºæŠ•å½±ï¼š[B, S, H] â†’ [B, S, output_dim]
    y = G.reshape(y, [batch_size * seq_len, hidden_dim])  # 3Dâ†’2D
    output = G.Linear(y, output_dim)
    output = G.reshape(output, [batch_size, seq_len, output_dim])  # 2Dâ†’3Dï¼šè¿˜åŸæ—¶åºè¾“å‡º
    
    return G, output


# ------------------------------
# 3. SchNet - ææ–™ç§‘å­¦/è®¡ç®—åŒ–å­¦çš„ä¸»æµGNNæ¨¡å‹
# å‚è€ƒè®ºæ–‡ï¼šSchNetâ€“A deep learning architecture for molecules and materials (2018)
# ------------------------------
def _schnet_interaction_block(
    G: OpGraph,
    x,
    edge_attr,
    batch_size: int,
    num_atoms: int,
    hidden_dim: int = 64,
):
    """SchNetæ ¸å¿ƒäº¤äº’å—ï¼ˆæ¡†æ¶å…¼å®¹ç‰ˆï¼‰"""
    # åŸå­ç‰¹å¾æŠ•å½±ï¼š[B, N, atom_dim] â†’ [BÃ—N, atom_dim] â†’ [BÃ—N, H] â†’ [B, N, H]
    x = G.reshape(x, [batch_size * num_atoms, G[x].out_shape[-1]])
    x_proj = G.Linear(x, hidden_dim)
    x_proj = G.reshape(x_proj, [batch_size, num_atoms, hidden_dim])
    
    # è¾¹ç‰¹å¾æŠ•å½±ï¼š[B, N, edge_dim] â†’ [BÃ—N, edge_dim] â†’ [BÃ—N, H] â†’ [B, N, H]
    edge_attr = G.reshape(edge_attr, [batch_size * num_atoms, G[edge_attr].out_shape[-1]])
    edge_proj = G.Linear(edge_attr, hidden_dim)
    edge_proj = G.reshape(edge_proj, [batch_size, num_atoms, hidden_dim])
    
    # äº¤äº’+æ®‹å·®ï¼šç»´åº¦å‡ä¸º[B, N, H]
    x_interact = G.add(x_proj, edge_proj)
    x_interact = G.relu(x_interact)
    x_interact = G.reshape(x_interact, [batch_size * num_atoms, hidden_dim])
    x_interact = G.Linear(x_interact, hidden_dim)
    x_interact = G.reshape(x_interact, [batch_size, num_atoms, hidden_dim])
    
    return G.add(x_proj, x_interact)


def schnnet(
    batch_size: int = 1,
    num_atoms: int = 32,
    atom_dim: int = 10,
    edge_dim: int = 4,
    output_dim: int = 1,
    hidden_dim: int = 64,
    num_interaction_layers: int = 3,
):
    """
    SchNet - ææ–™ç§‘å­¦/è®¡ç®—åŒ–å­¦çš„ä¸»æµGNNæ¨¡å‹
    ğŸ”¥ é¢†åŸŸåœ°ä½ï¼šæ›¿ä»£ä¼ ç»ŸDFTï¼ˆå¯†åº¦æ³›å‡½ç†è®ºï¼‰ï¼Œæˆä¸ºåˆ†å­æ€§è´¨é¢„æµ‹çš„å·¥ä¸šç•Œæ ‡å‡†
    """
    if num_atoms <= 0 or atom_dim <= 0 or edge_dim <= 0 or batch_size <= 0:
        raise ValueError("batch_sizeã€num_atomsã€atom_dimã€edge_dimå¿…é¡»ä¸ºæ­£æ•´æ•°")
    
    G = OpGraph()
    # è¾“å…¥1ï¼šåŸå­ç‰¹å¾ [B, num_atoms, atom_dim]
    atom_features = G.placeholder([batch_size, num_atoms, atom_dim], "atom_features")
    # è¾“å…¥2ï¼šè¾¹ç‰¹å¾ [B, num_atoms, num_atoms, edge_dim]
    edge_features = G.placeholder([batch_size, num_atoms, num_atoms, edge_dim], "edge_features")
    
    # è¾¹ç‰¹å¾èšåˆï¼š[B, N, N, E] â†’ [B, N, E]
    edge_agg = G.mean(edge_features, dim=2)
    
    # éª¨å¹²ç½‘ç»œ
    x = atom_features
    for _ in range(num_interaction_layers):
        x = _schnet_interaction_block(G, x, edge_agg, batch_size, num_atoms, hidden_dim)
    
    # å…¨å±€èšåˆï¼š[B, N, H] â†’ [B, H]
    x = G.reshape(x, [batch_size * num_atoms, hidden_dim])
    x_global = G.mean(x, dim=0, keepdims=True)
    x_global = G.reshape(x_global, [batch_size, hidden_dim])
    
    # è¾“å‡ºï¼š[B, output_dim]
    output = G.Linear(x_global, output_dim)
    return G, output


# ------------------------------
# å…¼å®¹æ—§æ¥å£ï¼ˆå¯é€‰ï¼‰
# ------------------------------
def Pinn(
    batch_size: int = 1,
    input_dim: int = 2,
    output_dim: int = 1,
    hidden_sizes: Optional[list] = None,
    activation: str = "tanh",
):
    """Pinnï¼ˆä¿ç•™æ¥å£ï¼Œå…¼å®¹åŸæœ‰ä»£ç ï¼‰"""
    if hidden_sizes is None:
        hidden_sizes = [64, 128, 256, 128, 64]
    G = OpGraph()
    x = G.placeholder([batch_size, input_dim], "physics_coords")
    for h in hidden_sizes:
        x = G.Linear(x, h)
        x = getattr(G, activation)(x)
    output = G.Linear(x, output_dim)
    return G, output